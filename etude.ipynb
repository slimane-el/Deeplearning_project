{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from principal_RBM_alpha import *\n",
    "from principal_DBN_alpha import *\n",
    "from principal_DNN_MNIST import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lire_alpha_digit(caractere_list, path_data):\n",
    "    caractere_list = [dict_az[el] for el in caractere_list]\n",
    "    print(caractere_list)\n",
    "    data = scipy.io.loadmat(path_data)\n",
    "    data = list(data['dat'][i] for i in caractere_list)\n",
    "    final_data = []\n",
    "    # For each letter\n",
    "    for i in range(len(caractere_list)):\n",
    "        data_tmp = [data[i][j].flatten() for j in range(39)]\n",
    "        final_data.append(np.vstack(data_tmp))\n",
    "        if np.vstack(data_tmp).shape[0] != 39:\n",
    "            raise ValueError\n",
    "\n",
    "    p = final_data[0].shape[1]\n",
    "    final_data = np.vstack(final_data)\n",
    "    final_data = np.resize(\n",
    "        final_data, (final_data.shape[0], 1, final_data.shape[1]))\n",
    "\n",
    "    return final_data, p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Alpha Digits\n",
    "Générer des images via RBM et DBN pour vérifier la bonne génération des caractères"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_az = {\n",
    "    '0':0, '1':1, '2':2, '3':3, '3':3, '4':4, '5':5, '6':6, '7':7, '8':8, '9':9, \n",
    "    'A':10, 'B':11, 'C':12, 'D':13, 'E':14, 'F':15, 'G':16, 'H':17, 'I':18,\n",
    "    'J':19, 'K':20, 'L':21, 'M':22, 'N':23, 'O':24, 'P':25, 'Q':26, 'R':27,\n",
    "    'S':28, 'T':29, 'U':30, 'V':31, 'W':32, 'X':33, 'Y':34, 'Z':35 \n",
    "}\n",
    "path_data = \"data/binaryalphadigs.mat\"\n",
    "nb_pixels = 20*16\n",
    "neurons = [200, 100, 50]\n",
    "epochs = [200, 300, 500]\n",
    "layers = []\n",
    "for neuron in neurons :\n",
    "    for epoch in epochs : \n",
    "        rbm_trained = []\n",
    "        for carac in list(dict_az.keys()):\n",
    "            data, nb_pixels = lire_alpha_digit([carac], path_data)\n",
    "            print(\"Caractère : \", carac)\n",
    "            rbm = RBM()\n",
    "            rbm.init_RBM(\n",
    "            p = nb_pixels, \n",
    "            q = neuron)\n",
    "            rbm.train_RBM(epochs=200, lr=0.1, batch_fraction=0.2, x=data, plot_error=False)\n",
    "            rbm_trained.append(rbm)\n",
    "\n",
    "        # afficher images\n",
    "        fig, axs = plt.subplots(5, 7, sharex=True, sharey=True)\n",
    "        fig.suptitle(f'RBM {neuron} neurons, {epoch} epochs')\n",
    "        for i in range(5):\n",
    "            for j in range(7):\n",
    "                rbm = rbm_trained[i*7 + j]\n",
    "                img = rbm.generer_image_RBM(100, 1)\n",
    "                axs[i, j].imshow(img[0].cpu(), cmap='Greys')\n",
    "        plt.show()\n",
    "        fig.savefig(f\"res/RBM-{neuron}neurons-{epoch}epochs.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train sur 2 caractères\n",
    "dict_az = {\n",
    "    '0':0, '1':1, '2':2, '3':3, '3':3, '4':4, '5':5, '6':6, '7':7, '8':8, '9':9, \n",
    "    'A':10, 'B':11, 'C':12, 'D':13, 'E':14, 'F':15, 'G':16, 'H':17, 'I':18,\n",
    "    'J':19, 'K':20, 'L':21, 'M':22, 'N':23, 'O':24, 'P':25, 'Q':26, 'R':27,\n",
    "    'S':28, 'T':29, 'U':30, 'V':31, 'W':32, 'X':33, 'Y':34, 'Z':35 \n",
    "}\n",
    "path_data = \"data/binaryalphadigs.mat\"\n",
    "nb_pixels = 20*16\n",
    "neurons = [200, 50]\n",
    "epochs = [200, 500]\n",
    "carac = [\"A\", \"B\", \"C\"]#list(dict_az.keys()) # [\"A\", \"B\", \"C\", \"D\", ]\n",
    "\n",
    "for neuron in neurons :\n",
    "    for epoch in epochs : \n",
    "        data, nb_pixels = lire_alpha_digit(carac, path_data)\n",
    "        rbm = RBM()\n",
    "        rbm.init_RBM(\n",
    "        p = nb_pixels, \n",
    "        q = neuron)\n",
    "        rbm.train_RBM(epochs=200, lr=0.1, batch_fraction=0.2, x=data, plot_error=False)\n",
    "        img = rbm.generer_image_RBM(100, 10)\n",
    "        # afficher images\n",
    "        fig, axs = plt.subplots(2, 5, sharex=True, sharey=True)\n",
    "        fig.suptitle(f'RBM {neuron} neurons, {epoch} epochs')\n",
    "        for i in range(2):\n",
    "            for j in range(5):\n",
    "                axs[i, j].imshow(img[i*5 + j].cpu(), cmap='Greys')\n",
    "        plt.show()\n",
    "        fig.savefig(f\"res/RBM-ABC-{neuron}neurons-{epoch}epochs.png\")\n",
    "           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DBN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_az = {\n",
    "    '0':0, '1':1, '2':2, '3':3, '3':3, '4':4, '5':5, '6':6, '7':7, '8':8, '9':9, \n",
    "    'A':10, 'B':11, 'C':12, 'D':13, 'E':14, 'F':15, 'G':16, 'H':17, 'I':18,\n",
    "    'J':19, 'K':20, 'L':21, 'M':22, 'N':23, 'O':24, 'P':25, 'Q':26, 'R':27,\n",
    "    'S':28, 'T':29, 'U':30, 'V':31, 'W':32, 'X':33, 'Y':34, 'Z':35 \n",
    "}\n",
    "path_data = \"data/binaryalphadigs.mat\"\n",
    "nb_pixels = 20*16\n",
    "neurons = [200, 100, 50]\n",
    "epochs = [100, 300, 500]\n",
    "# layers = []\n",
    "for neuron in neurons :\n",
    "    for epoch in epochs : \n",
    "        dbn_trained = []\n",
    "        for carac in list(dict_az.keys()):\n",
    "            data, nb_pixels = lire_alpha_digit([carac], path_data)\n",
    "            print(\"Caractère : \", carac)\n",
    "            dbn = DBN()\n",
    "            Q = [nb_pixels, neuron, neuron]\n",
    "            dbn.init_DBN(\n",
    "                Q = Q\n",
    "                )\n",
    "            dbn.train_DBN(epochs=[epoch], lr=0.1, batch_fraction=0.2, x=data, plot_error=False)\n",
    "            dbn_trained.append(dbn)\n",
    "\n",
    "        # afficher images\n",
    "        fig, axs = plt.subplots(5, 7, sharex=True, sharey=True)\n",
    "        fig.suptitle(f'DBN {neuron} neurons, {epoch} epochs')\n",
    "        for i in range(5):\n",
    "            for j in range(7):\n",
    "                dbn = dbn_trained[i*7 + j]\n",
    "                img = dbn.generer_image_DBN(100, 1)\n",
    "                axs[i, j].imshow(img[0].cpu(), cmap='Greys')\n",
    "        plt.show()\n",
    "        fig.savefig(f\"res/DBN-{neuron}neurons-{epoch}epochs.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train sur 2 caractères\n",
    "dict_az = {\n",
    "    '0':0, '1':1, '2':2, '3':3, '3':3, '4':4, '5':5, '6':6, '7':7, '8':8, '9':9, \n",
    "    'A':10, 'B':11, 'C':12, 'D':13, 'E':14, 'F':15, 'G':16, 'H':17, 'I':18,\n",
    "    'J':19, 'K':20, 'L':21, 'M':22, 'N':23, 'O':24, 'P':25, 'Q':26, 'R':27,\n",
    "    'S':28, 'T':29, 'U':30, 'V':31, 'W':32, 'X':33, 'Y':34, 'Z':35 \n",
    "}\n",
    "path_data = \"data/binaryalphadigs.mat\"\n",
    "nb_pixels = 20*16\n",
    "neurons = [200]\n",
    "epochs = [200]\n",
    "nb_layers = [2, 3, 4]\n",
    "carac = list(dict_az.keys()) # [\"A\", \"B\", \"C\", \"D\", ]\n",
    "\n",
    "for neuron in neurons :\n",
    "    for epoch in epochs : \n",
    "        for layer in nb_layers:\n",
    "            data, nb_pixels = lire_alpha_digit(carac, path_data)\n",
    "            dbn = DBN()\n",
    "            Q = [nb_pixels] + [neuron]*(layer)\n",
    "            dbn.init_DBN(\n",
    "            Q=Q)\n",
    "            dbn.train_DBN(epochs=[200], lr=0.1, batch_fraction=0.2, x=data, plot_error=False)\n",
    "            img = dbn.generer_image_DBN(100, 36)\n",
    "            # afficher images\n",
    "            fig, axs = plt.subplots(6, 6, sharex=True, sharey=True)\n",
    "            fig.suptitle(f'DBN {neuron} neurons, {epoch} epochs, {layer} layers')\n",
    "            for i in range(6):\n",
    "                for j in range(6):\n",
    "                    axs[i, j].imshow(img[i*6 + j].cpu(), cmap='Greys')\n",
    "            plt.show()\n",
    "            fig.savefig(f\"res/DBN-all-{neuron}neurons-{epoch}epochs-{layer}layers.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement des données\n",
    "import torch \n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dset\n",
    "# if not exist, download mnist dataset\n",
    "train_set = dset.MNIST(root='./data', train=True, transform=None, download=True)\n",
    "test_set = dset.MNIST(root='./data', train=False, transform=None, download=True)\n",
    "batch_size = 100\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "                 dataset=train_set,\n",
    "                 batch_size=batch_size,\n",
    "                 shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "                dataset=test_set,\n",
    "                batch_size=batch_size,\n",
    "                shuffle=False)\n",
    "\n",
    "train_mnist = (train_set.train_data > 127).float().to(device)\n",
    "test_mnist = (test_set.train_data > 127).float().to(device)\n",
    "train_mnist = train_mnist.view(train_mnist.shape[0], -1)\n",
    "test_mnist = test_mnist.view(test_mnist.shape[0], -1)\n",
    "nb_classes = len(train_set.class_to_idx)\n",
    "labels_train_mnist = train_set.train_labels\n",
    "labels_test_mnist = test_set.test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_mnist.view((train_mnist.shape[0], 1, -1))\n",
    "# one hot encoding of labels, put 1 on the idx \n",
    "y_train = torch.zeros(train_mnist.shape[0], nb_classes)\n",
    "y_train[torch.arange(train_mnist.shape[0]), labels_train_mnist] = 1\n",
    "y_train = y_train.view((y_train.shape[0], 1, -1))\n",
    "y_train.shape\n",
    "x_train = x_train.double().to(device)\n",
    "y_train = y_train.double().to(device)\n",
    "print(\"x_train shape : \", x_train.shape)\n",
    "print(\"y_train shape : \", y_train.shape)\n",
    "\n",
    "x_test = test_mnist.view((test_mnist.shape[0], 1, -1))\n",
    "# one hot encoding of labels, put 1 on the idx \n",
    "y_test = torch.zeros(test_mnist.shape[0], nb_classes)\n",
    "y_test[torch.arange(test_mnist.shape[0]), labels_test_mnist] = 1\n",
    "y_test = y_test.view((y_test.shape[0], 1, -1))\n",
    "y_test.shape\n",
    "x_test = x_test.double().to(device)\n",
    "y_test = y_test.double().to(device)\n",
    "print(\"x_test shape : \", x_test.shape)\n",
    "print(\"y_test shape : \", y_test.shape)\n",
    "\n",
    "x_traintest = torch.concat([x_train, x_test])\n",
    "y_traintest = torch.concat([y_train, y_test])\n",
    "x_traintest.shape, y_traintest.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FIGURE 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIGURE 1\n",
    "list_nb_layers = [1, 2, 3, 4] # liste des hidden layers /!\\ DNN rajoute une couche de plus qu'indiquer sur Q\n",
    "nb_neurons = 200\n",
    "nb_layers = 1\n",
    "nb_pixels = x_train.shape[2]\n",
    "res_dnn1 = []\n",
    "res_dnn2 = []\n",
    "for layer in list_nb_layers:\n",
    "    Q = [nb_pixels] + [nb_neurons]*(nb_layers)\n",
    "    dnn1 = DNN()\n",
    "    dnn2 = DNN()\n",
    "    dnn1.init_DNN(\n",
    "        Q = Q,\n",
    "        nb_classes=nb_classes\n",
    "        )\n",
    "    dnn2.init_DNN(\n",
    "        Q = Q,\n",
    "        nb_classes=nb_classes\n",
    "        )\n",
    "    dnn1.pretrain_DNN(epochs=[100], lr=0.2, batch_fraction=0.005,\n",
    "                     x=x_train, plot_error=True)\n",
    "    dnn1.retropropagation(epochs=200, lr=0.2, batch_fraction=0.005, X=x_train,\n",
    "                            Y=y_train, plot_error=True)\n",
    "    dnn2.retropropagation(epochs=200, lr=0.2, batch_fraction=0.005, X=x_train,\n",
    "                            Y=y_train, plot_error=True)\n",
    "    res_dnn1.append(dnn1.test_DNN(x_traintest, y_traintest))\n",
    "    res_dnn2.append(dnn2.test_DNN(x_traintest, y_traintest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "res_dnn1_np = np.array([el.numpy() for el in res_dnn1])\n",
    "res_dnn2_np = np.array([el.numpy() for el in res_dnn2])\n",
    "\n",
    "sns.lineplot(x=[1, 2, 3, 4], y=res_dnn1_np, label=\"Pre-train\")\n",
    "sns.lineplot(x=[1, 2, 3, 4], y=res_dnn2_np, label=\"No pre-train\")\n",
    "plt.xlabel(\"Number of hidden layer\")\n",
    "plt.ylabel(\"Classification error rate\")\n",
    "plt.savefig(f\"res/fig1.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FIGURE 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIGURE 2\n",
    "list_nb_neurons = [100, 200, 300, 500]\n",
    "nb_pixels = x_train.shape[2]\n",
    "res_dnn1_neuron = []\n",
    "res_dnn2_neuron = []\n",
    "for neuron in list_nb_neurons:\n",
    "    Q = [nb_pixels] + [neuron]\n",
    "    dnn1 = DNN()\n",
    "    dnn2 = DNN()\n",
    "    dnn1.init_DNN(\n",
    "        Q = Q,\n",
    "        nb_classes=nb_classes\n",
    "        )\n",
    "    dnn2.init_DNN(\n",
    "        Q = Q,\n",
    "        nb_classes=nb_classes\n",
    "        )\n",
    "    dnn1.pretrain_DNN(epochs=[100], lr=0.1, batch_fraction=0.01,\n",
    "                     x=x_train, plot_error=True)\n",
    "    dnn1.retropropagation(epochs=200, lr=0.1, batch_fraction=0.01, X=x_train,\n",
    "                            Y=y_train, plot_error=True)\n",
    "    dnn2.retropropagation(epochs=200, lr=0.1, batch_fraction=0.01, X=x_train,\n",
    "                            Y=y_train, plot_error=True)\n",
    "    res_dnn1_neuron.append(dnn1.test_DNN(x_traintest, y_traintest))\n",
    "    res_dnn2_neuron.append(dnn2.test_DNN(x_traintest, y_traintest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "res_dnn1_np = np.array([el.numpy() for el in res_dnn1_neuron])\n",
    "res_dnn2_np = np.array([el.numpy() for el in res_dnn2_neuron])\n",
    "sns.lineplot(x=[100, 200, 300, 500], y=res_dnn1_np, label=\"Pre-train\")\n",
    "sns.lineplot(x=[100, 200, 300, 500], y=res_dnn2_np, label=\"No pre-train\")\n",
    "plt.xlabel(\"Number of neurons per layer\")\n",
    "plt.ylabel(\"Classification error rate\")\n",
    "plt.savefig(f\"res/fig2.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FIGURE 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIGURE 3\n",
    "list_trainsize = [1000, 3000, 7000, 10000, 30000, 60000]\n",
    "nb_pixels = x_train.shape[2]\n",
    "res_dnn1_trainsize = []\n",
    "res_dnn2_trainsize = []\n",
    "for size in list_trainsize:\n",
    "    Q = [nb_pixels, 200, 200]\n",
    "    shuffled_indices = np.arange(x_train.shape[0])\n",
    "    np.random.shuffle(shuffled_indices)\n",
    "    x_shuffled = x_train[shuffled_indices]\n",
    "    Y_shuffled = y_train[shuffled_indices]\n",
    "    x_reduce = x_shuffled[0:size]\n",
    "    y_reduce = Y_shuffled[0:size]\n",
    "    dnn1 = DNN()\n",
    "    dnn2 = DNN()\n",
    "    dnn1.init_DNN(\n",
    "        Q = Q,\n",
    "        nb_classes=nb_classes\n",
    "        )\n",
    "    dnn2.init_DNN(\n",
    "        Q = Q,\n",
    "        nb_classes=nb_classes\n",
    "        )\n",
    "    dnn1.pretrain_DNN(epochs=[100], lr=0.1, batch_fraction=0.01,\n",
    "                     x=x_reduce, plot_error=True)\n",
    "    dnn1.retropropagation(epochs=200, lr=0.1, batch_fraction=0.01, X=x_reduce,\n",
    "                            Y=y_reduce, plot_error=True)\n",
    "    dnn2.retropropagation(epochs=200, lr=0.1, batch_fraction=0.01, X=x_reduce,\n",
    "                            Y=y_reduce, plot_error=True)\n",
    "    res_dnn1_trainsize.append(dnn1.test_DNN(x_traintest, y_traintest))\n",
    "    res_dnn2_trainsize.append(dnn2.test_DNN(x_traintest, y_traintest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "res_dnn1_np = np.array([el.numpy() for el in res_dnn1_trainsize])\n",
    "res_dnn2_np = np.array([el.numpy() for el in res_dnn2_trainsize])\n",
    "sns.lineplot(x=[1000, 3000, 7000, 10000, 30000, 60000], y=res_dnn1_np, label=\"Pre-train\")\n",
    "sns.lineplot(x=[1000, 3000, 7000, 10000, 30000, 60000], y=res_dnn2_np, label=\"No pre-train\")\n",
    "plt.xlabel(\"Training size\")\n",
    "plt.ylabel(\"Classification error rate\")\n",
    "plt.yscale('log')\n",
    "plt.savefig(f\"res/fig3.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tuning of hyperparameters\n",
    "lr = [0.1, 0.15, 0.2]\n",
    "hidden_layers = [1, 2, 3]\n",
    "train_size = [60000] #30000, \n",
    "batch_size = [0.005] #0.01, \n",
    "neurons = [500] # 300, 400, \n",
    "epochs_pretrain = [300]\n",
    "epoch_backprop = [500]\n",
    "import itertools\n",
    "a = [lr, hidden_layers, train_size, batch_size, neurons,\n",
    "         epochs_pretrain, epoch_backprop]\n",
    "grid_search = list(itertools.product(*a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "t1 = time.time()\n",
    "nb_pixels = x_train.shape[2]\n",
    "res_comb = {}\n",
    "for comb in grid_search :\n",
    "    print(comb)\n",
    "    lr, hidden_layers, size, batch_size, nb_neurons,epochs_pretrain, epoch_backprop = comb\n",
    "    Q = [nb_pixels] + [nb_neurons]*(hidden_layers)\n",
    "    shuffled_indices = np.arange(x_train.shape[0])\n",
    "    np.random.shuffle(shuffled_indices)\n",
    "    x_shuffled = x_train[shuffled_indices]\n",
    "    Y_shuffled = y_train[shuffled_indices]\n",
    "    x_reduce = x_shuffled[0:size]\n",
    "    y_reduce = Y_shuffled[0:size]\n",
    "    dnn1 = DNN()\n",
    "    dnn1.init_DNN(\n",
    "        Q = Q,\n",
    "        nb_classes=nb_classes\n",
    "        )\n",
    "    dnn1.pretrain_DNN(epochs=[epochs_pretrain], lr=lr, batch_fraction=batch_size,\n",
    "                     x=x_reduce, plot_error=True)\n",
    "    dnn1.retropropagation(epochs=epoch_backprop, lr=lr, batch_fraction=batch_size,\n",
    "                          X=x_reduce,\n",
    "                            Y=y_reduce, plot_error=True)\n",
    "    res_comb[comb] = dnn1.test_DNN(x_traintest, y_traintest).numpy()\n",
    "    t2 = time.time()\n",
    "    print(res_comb[comb])\n",
    "    print('Execution time 1 comb:', t2-t1, 'seconds')\n",
    "\n",
    "t3 = time.time()\n",
    "elapsed_time = t3 - t1\n",
    "print('Execution time:', elapsed_time, 'seconds')\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
